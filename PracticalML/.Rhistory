library(AppliedPredictiveModeling)
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
head(AlzheimerDisease, 10)
head(AlzheimerDisease)
AlzheimerDisease
a<-data(AlzheimerDisease)
head(a,10)
head(a,30)
summary(AlzheimerDisease)
data(AlzheimerDisease)
AlzheimerDisease
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(concrete,5)
concrete2<-cut2(training$Cement,g=3)
?cut
plot(index,CompressiveStrength,col=Cement)
dim(training)
?dim
plot(training$index,training$CompressiveStrength,col=training$Cement)
head(training)
plot(training$CompressiveStrength, main="vs. Cement", col=training$Cement)
plot(training$CompressiveStrength, main="vs. Cement", col=training$Cement)
plot(cement2$CompressiveStrength, main="vs. Cement", col=cement2$Cement)
plot(training$CompressiveStrength, main="vs. Cement")
cement2<-cut2(training,g=3)
cement2<-cut2(training$Cement,g=3)
plot(cement2$CompressiveStrength, main="vs. Cement", col=cement2$Cement)
plot(CompressiveStrength, main="vs. Cement", col=Cement)
class(cement2)
head(cement2,5)
qplot(CompressiveStrength, data=cement2, fill=Cement)
qplot(cement2, CompressiveStrength, data=training, fill=Cement)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(SuperPlasticizer, data=training)
hist(training$SuperPlasticizer, data=training)
hist(training$SuperPlasticizer)
?hist
a<-training$SuperPlasticizer
hist(a)
a
head(training)
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer))
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer)+1)
unique(training$Superplasticizer)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
nrow(training)
nrow(testing)
head(training,10)
head(testing,10)
?createDataPartition
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
nrow(training)
nrow(testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(CompressiveStrength)
plot(training$CompressiveStrength)
summary(training)
plot(training$CompressiveStrength, col=cut2(training$Cement))
plot(training$CompressiveStrength, col=cut2(training$FlyAsh))
plot(training$CompressiveStrength, col=cut2(training$Age))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer)+1)
hist(log10(training$Superplasticizer+1)
)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training,2)
names(training)
data<-subset(AlzheimerDisease,select=c(IL_11, IL_13, IL_16, IL_17E, IL_1alpha, IL_3, IL_4, IL_5, IL_6, IL_7, IL_6_Receptor, IL_8))
data<-subset(training,select=c(IL_11, IL_13, IL_16, IL_17E, IL_1alpha, IL_3, IL_4, IL_5, IL_6, IL_7, IL_6_Receptor, IL_8))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
data<-subset(AlzheimerDisease,select=c(IL_11, IL_13, IL_16, IL_17E, IL_1alpha, IL_3, IL_4, IL_5, IL_6, IL_7, IL_6_Receptor, IL_8))
data<-subset(data(AlzheimerDisease),select=c(IL_11, IL_13, IL_16, IL_17E, IL_1alpha, IL_3, IL_4, IL_5, IL_6, IL_7, IL_6_Receptor, IL_8))
data<-subset(AlzheimerDisease,select=c(IL_11, IL_13, IL_16, IL_17E, IL_1alpha, IL_3, IL_4, IL_5, IL_6, IL_7, IL_6_Receptor, IL_8))
data<-subset(training,select=c(IL_11, IL_13, IL_16, IL_17E, IL_1alpha, IL_3, IL_4, IL_5, IL_6, IL_7, IL_6_Receptor, IL_8))
preProc<-proProcess(log10(data+1), method="pca")
preProc<-preProcess(log10(data+1), method="pca")
preProc
preProc[,1]
preProc<-preProcess(log10(data+1), method="pca", pcaComp=2)
library(stats)
prComp<-prcomp(log10(data+1))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
data<-training[,c(IL_11, IL_13, IL_16, IL_17E, IL_1alpha, IL_3, IL_4, IL_5, IL_6, IL_7, IL_6_Receptor, IL_8)]
data<-training[,c("IL_11", IL_13, IL_16, IL_17E, IL_1alpha, IL_3, IL_4, IL_5, IL_6, IL_7, IL_6_Receptor, IL_8)]
data<-training[,c("IL_11", "IL_13", "IL_16", "IL_17E", "IL_1alpha", "IL_3", "IL_4", "IL_5", "IL_6", "IL_7", "IL_6_Receptor", "IL_8")]
prComp<-prcomp(data)
prComp$rotation
preProc<-preProcess(log10(training[,c("IL_11", IL_13, IL_16, IL_17E, IL_1alpha, IL_3, IL_4, IL_5, IL_6, IL_7, IL_6_Receptor, IL_8)]+1),method="pca", pcaComp=2)
preProc<-preProcess(log10(training[,c("IL_11", "IL_13", "IL_16", "IL_17E", "IL_1alpha", "IL_3", "IL_4", "IL_5", "IL_6", "IL_7", "IL_6_Receptor", "IL_8")]+1),method="pca", pcaComp=2)
preProc<-preProcess(training[,c("IL_11", "IL_13", "IL_16", "IL_17E", "IL_1alpha", "IL_3", "IL_4", "IL_5", "IL_6", "IL_7", "IL_6_Receptor", "IL_8")]),method="pca", pcaComp=2)
prComp<-prcomp(data)
plot(prComp[,1], prComp[,2])
plot(prComp$x[,1], prComp$x[,2])
data<-training[,c("IL_11", "IL_13", "IL_16", "IL_17E", "IL_1alpha", "IL_3", "IL_4", "IL_5", "IL_6", "IL_7", "IL_6_Receptor", "IL_8", "diagnosis")]
modelFit<-train(data$diagnosis, method="glm", preProcess="pca", data=data)
modelFit<-train(data$diagnosis ~ ., method="glm", preProcess="pca", data=data)
update.packages()
y
y
devtools::install_github/('rstudio/shinyapps')
library(devtools)
devtools::install_github/('rstudio/shinyapps')
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
install_github('rstudio/shinyapps')
install_github('ropensci/plotly')
library(ISLR)
library(ggplot2)
library(caret)
#READING DATA
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")
dim(training)
dim(testing)
library(devtools)
install_github('slidify','ramnathv')
install_github('ramnathv/slidify')
devtools::build_github_devtools()
library(devtools)
install_github('ramnathv/slidify')
sessionInfo()
install.packages('devtools')
library(devtools)
install_github('ramnathv/slidify')
libary(devtools)
library(devtools)
install.packages('devtools')
install_github('ramnathv/slidify')
library(devtools)
library(devtools)
install_github('ramnathv/slidify')
install_github('dplyr')
install_packages('slidify-master.tar',repos=NULL)
install.packages('slidify-master.tar',repos=NULL)
install.packages('C:/Users/dk.benavides20/Downloads/slidify-master.tar',repos=NULL)
install.packages('C:/Users/dk.benavides20/Downloads/slidify-master.zip',repos=NULL)
library(slidify)
install.packages('C:/Users/dk.benavides20/Downloads/slidify-master.zip',repos=NULL)
install.packages(file.choose(),repos=NULL)
library(slidify)
install.packages(file.choose(),repos=NULL)
install.packages(file.choose(),repos=NULL)
library(slidify)
library('slidify')
install.packages(file.choose(),repos=NULL)
install.packages(file.choose(),repos=NULL)
library('slidify')
install.packages(file.choose(),repos=NULL)
library('slidify')
library(slidify)
install.packages(file.choose(),repos=NULL)
library(slidify)
install.packages(file.choose(),repos=NULL, type='source')
library(slidify)
require(devtools)
install_github('slidify', 'ramnathv')
require(devtools)
install_github('ramnathv/slidify')
require(devtools)
install_github('hadley/dplyr')
install.packages(dplyr)
install.packages('dplyr')
setwd("C:/DIANA BENAVIDES/Courses/Data Scientist Specialization/Practical ML/CourseProject")
#SOLUTION WITH CROSS-VALIDATION
library(ISLR)
library(ggplot2)
library(caret)
library(randomForest)
#READING DATA
training<-read.csv("pml-training.csv")
validation<-read.csv("pml-testing.csv")
#Leave it as validation data
dim(training)
dim(testing)
#SOLUTION WITH CROSS-VALIDATION
library(ISLR)
library(ggplot2)
library(caret)
library(randomForest)
#READING DATA
training<-read.csv("pml-training.csv")
validation<-read.csv("pml-testing.csv")
#Leave it as validation data
dim(training)
dim(validation)
#PRE-PROCESSING DATA
#Divide by numeric and factor variables
numericValidation<-validation[sapply(validation,is.numeric)]
vars<-colnames(training) %in% colnames(numericValidation)
numericTraining <- training[vars]
vars2<-colnames(numericValidation) %in% colnames(numericTraining)
numericValidation <- numericValidation[vars2]
factorTraining <- training[sapply(training,is.factor)]
factorValidation <- validation[sapply(validation,is.factor)]
for(i in 1:ncol(numericTraining)){
numericTraining[is.na(numericTraining[,i]), i] <- mean(numericTraining[,i], na.rm = TRUE)
numericValidation[is.na(numericTraining[,i]), i] <- mean(numericTraining[,i], na.rm = TRUE)
}
preObj<-preProcess(numericTraining,method=c("center","scale"))
numericTraining<-predict(preObj, numericTraining, )
head(numericTraining,10)
preObj<-preProcess(numericValidation,method=c("center","scale"))
numericValidation<-predict(preObj, numericValidation, )
finalTraining<-cbind.data.frame(numericTraining,factorTraining$classe)
colnames(finalTraining)[57]<-"classe"
finalTraining<-as.data.frame(finalTraining)
#Remove useless columns
finalTraining<-finalTraining[,-1]
finalTraining<-finalTraining[,-1]
finalTraining<-finalTraining[,-1]
finalTraining<-finalTraining[,-1]
finalValidation<-as.data.frame(numericValidation)
#finalValidation<-as.numeric(finalValidation)
finalValidation$classe<-c("A","E","I","O","U","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A")
finalValidation$classe<-as.factor(finalValidation$classe)
finalValidation<-finalValidation[,-1]
finalValidation<-finalValidation[,-1]
finalValidation<-finalValidation[,-1]
finalValidation<-finalValidation[,-1]
names(finalValidation)<-names(finalTraining)
names(finalValidation)
names(finalTraining)
nrow(finalValidation)
nrow(finalTraining)
ncol(finalValidation)
ncol(finalTraining)
fitControl <- trainControl(method = "repeatedcv",number = 10,repeats = 10)
set.seed(825)
modelFit<-train(finalTraining$classe ~ ., method="rf", data=finalTraining[,-53], trControl=fitControl)
testPC<-predict(preProc, finalValidation[,-53])
table(finalValidation$classe, predict(modelFit, testPC))
modelFit
table(finalValidation$classe, predict(modelFit, finalValidation[,-53]))
finalValidation[,53]
table(finalValidation$classe, predict(modelFit, finalValidation[1,-53]))
table(finalValidation$classe[1], predict(modelFit, finalValidation[1,-53]))
table(finalValidation$classe[2], predict(modelFit, finalValidation[2,-53]))
table(finalValidation$classe[3], predict(modelFit, finalValidation[3,-53]))
table(finalValidation$classe[4], predict(modelFit, finalValidation[4,-53]))
validation<-read.csv("pml-testing.csv")
numericValidation<-validation[sapply(validation,is.numeric)]
vars<-colnames(training) %in% colnames(numericValidation)
vars2<-colnames(numericValidation) %in% colnames(numericTraining)
numericValidation <- numericValidation[vars2]
factorValidation <- validation[sapply(validation,is.factor)]
for(i in 1:ncol(numericTraining)){
numericValidation[is.na(numericTraining[,i]), i] <- mean(numericTraining[,i], na.rm = TRUE)
}
preObj<-preProcess(numericValidation,method=c("center","scale"))
numericValidation<-predict(preObj, numericValidation, )
finalValidation<-as.data.frame(numericValidation)
#finalValidation<-as.numeric(finalValidation)
finalValidation$classe<-c("A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A")
finalValidation$classe<-as.factor(finalValidation$classe)
finalValidation<-finalValidation[,-1]
finalValidation<-finalValidation[,-1]
finalValidation<-finalValidation[,-1]
finalValidation<-finalValidation[,-1]
names(finalValidation)<-names(finalTraining)
table(finalValidation$classe[1], predict(modelFit, finalValidation[1,-53]))
table(finalValidation$classe[2], predict(modelFit, finalValidation[2,-53]))
table(finalValidation$classe[3], predict(modelFit, finalValidation[3,-53]))
table(finalValidation$classe[5], predict(modelFit, finalValidation[5,-53]))
table(finalValidation$classe[6], predict(modelFit, finalValidation[6,-53]))
table(finalValidation$classe[7], predict(modelFit, finalValidation[7,-53]))
table(finalValidation$classe[8], predict(modelFit, finalValidation[8,-53]))
table(finalValidation$classe[9], predict(modelFit, finalValidation[9,-53]))
table(finalValidation$classe[10], predict(modelFit, finalValidation[10,-53]))
table(finalValidation$classe[11], predict(modelFit, finalValidation[11,-53]))
table(finalValidation$classe[12], predict(modelFit, finalValidation[12,-53]))
table(finalValidation$classe[13], predict(modelFit, finalValidation[13,-53]))
table(finalValidation$classe[14], predict(modelFit, finalValidation[14,-53]))
table(finalValidation$classe[15], predict(modelFit, finalValidation[15,-53]))
table(finalValidation$classe[16], predict(modelFit, finalValidation[16,-53]))
table(finalValidation$classe[17], predict(modelFit, finalValidation[17,-53]))
table(finalValidation$classe[18], predict(modelFit, finalValidation[18,-53]))
table(finalValidation$classe[19], predict(modelFit, finalValidation[19,-53]))
table(finalValidation$classe[20], predict(modelFit, finalValidation[20,-53]))
#SOLUTION WITH CROSS-VALIDATION
library(ISLR)
library(ggplot2)
library(caret)
library(randomForest)
#READING DATA
training<-read.csv("pml-training.csv")
validation<-read.csv("pml-testing.csv")
#Leave it as validation data
dim(training)
dim(validation)
#PRE-PROCESSING DATA
#Divide by numeric and factor variables
numericValidation<-validation[sapply(validation,is.numeric)]
vars<-colnames(training) %in% colnames(numericValidation)
numericTraining <- training[vars]
vars2<-colnames(numericValidation) %in% colnames(numericTraining)
numericValidation <- numericValidation[vars2]
factorTraining <- training[sapply(training,is.factor)]
factorValidation <- validation[sapply(validation,is.factor)]
#Replace missing values
#columns and their means
for(i in 1:ncol(numericTraining)){
numericTraining[is.na(numericTraining[,i]), i] <- mean(numericTraining[,i], na.rm = TRUE)
numericValidation[is.na(numericTraining[,i]), i] <- mean(numericTraining[,i], na.rm = TRUE)
}
#Since most of the variables have large standard deviations, standardizing all numeric variables
#numericTraining<-as.data.frame(apply(numericTraining, 1, function(x) ((x[!is.na(x)] - mean(x[!is.na(x)])) / sd(x[!is.na(x)]))))
#numericTraining<-t(numericTraining)
preObj<-preProcess(numericTraining,method=c("center","scale"))
numericTraining<-predict(preObj, numericTraining, )
#numericValidation<-as.data.frame(apply(numericValidation, 1, function(x) ((x[!is.na(x)] - mean(x[!is.na(x)])) / sd(x[!is.na(x)]))))
#numericValidation<-t(numericValidation)
preObj<-preProcess(numericValidation,method=c("center","scale"))
numericValidation<-predict(preObj, numericValidation, )
#Since all of the factor variables seem to be noise, or identifiers, they are removed from analysis
finalTraining<-cbind.data.frame(numericTraining,factorTraining$classe)
colnames(finalTraining)[57]<-"classe"
finalTraining<-as.data.frame(finalTraining)
#Remove useless columns
finalTraining<-finalTraining[,-1]
finalTraining<-finalTraining[,-1]
finalTraining<-finalTraining[,-1]
finalTraining<-finalTraining[,-1]
finalValidation<-as.data.frame(numericValidation)
#finalValidation<-as.numeric(finalValidation)
finalValidation$classe<-c("A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","A")
finalValidation$classe<-as.factor(finalValidation$classe)
finalValidation<-finalValidation[,-1]
finalValidation<-finalValidation[,-1]
finalValidation<-finalValidation[,-1]
finalValidation<-finalValidation[,-1]
names(finalValidation)<-names(finalTraining)
#Preprocessing
preProc<-preProcess(finalTraining[,-53], method="pca", na.remove=T)
trainPC<-predict(preProc, finalTraining[,-53])
fitControl <- trainControl(method = "repeatedcv",number = 10,repeats = 10)
#PREDICTING (with PCA)
set.seed(825)
modelFit<-train(finalTraining$classe ~ ., method="rf", data=finalTraining[,-53], trControl=fitControl)
fitControl <- trainControl(method = "repeatedcv",number = 10,repeats = 10)
#PREDICTING (with PCA)
set.seed(825)
modelFit<-train(finalTraining$classe ~ ., method="rf", data=trainPC, trControl=fitControl)
